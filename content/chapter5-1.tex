\chapter{Wiener-Prozess}

\begin{beschreibung}
Im Jahr 1827 beobachtete Robert Brown die Bewegungen von Pollen in Wasser und erkannte eine unregelmäßige Bewegung. Der Durchbruch in der Beschreibung dieses Verhaltens gelang 1905 von Albert Einstein, unabhängig von vorherigen wichtigen Arbeiten zu diesem Thema, indem er die Wärmebewegung der Moleküle im Wasser betrachtete. Dazu musste er jedoch die Existenz eines stochastischen Prozesses postulieren, die erstmals 1923 vom US-Amerikaner Norbert Wiener (*26.11.1894 -- \textdagger 18.03.1964) bewiesen wurde.
\end{beschreibung}

Wiener-Prozesse finden besonders in der Physik, in den Ingenieurs-Wissenschaften und in der Finanzmathematik breite Anwendung. Im Gegensatz zu den Prozessen, die wir bisher kennengelernt haben, sind Wiener Prozesse sowohl in der Zeit als auch im Zustandsraum stetig.

\section{Definition und einfache Eigenschaften}

\begin{definition}[Wiener-Prozess]\label{Nummer5.1.1}
Ein $\R$-wertiger stochastischer Prozess $(W_t)_{t \geq 0}$ heißt \deftxt{Wiener-Prozess}\index{Wiener-Prozess} oder \deftxt{Brownsche Bewegung}\index{Brownsche Bewegung}, wenn die folgenden Eigenschaften erfüllt sind:
\begin{enumerate}
	\item\label{N511A1} Es gilt $W_0 = 0$ $P$-fast sicher.
	\item\label{N511A2} Der Prozess $(W_t)$ hat unabhängige Zuwächse.
	\item\label{N511A3} Die Zuwächse $W_{s+t} - W_s$ sind $\sN(0,t)$-verteilt für alle $s \geq 0$ und $t > 0$.
	\item\label{N511A4} Der Prozess $(W_t)$ ist stetig, $P$-fast alle Pfade sind also stetig.
\end{enumerate}
\end{definition}

Die Existenz eines stochastischen Prozesses, der \ref{N511A1} -- \ref{N511A3} erfüllt, ist mit dem, was wir bisher kennengelernt haben, nicht besonders schwierig. Die Stetigkeit als zusätzliche Eigenschaft stellt sich schwieriger beim Beweis der Existenz heraus.

Man nennt einen stochastischen Prozess \deftxt{Lévy-Prozess}\index{Lévy-Prozess}, wenn die Zuwächse unabhängig und stationär sind. Homogene Poissonprozesse und Wiener-Prozesse sind Beispiele hierfür.

Die drei ersten Eigenschaften in Definition \ref{Nummer5.1.1} legen die endlich-dimensionalen Randverteilungen bereits fest und sichern damit die Eindeutigkeit. Wir werden dies später noch genauer untersuchen.

\minisec{Multivariate Normalverteilung}

Wir wollen an dieser Stelle nochmals an multivariate Normalverteilungen erinnern und unseren Kenntnisstand aus der Wahrscheinlichkeitstheorie ergänzen. Für mehr Details verweisen wir auf \cite[Kap. 7]{MEINTRUP}. 

Sei $\mu \in \R^d$ und $\Sigma$ eine strikt positiv definite und symmetrische $(d \times d)$-Matrix. Dann hat die multivariate Normalverteilung $\sN(\mu, \Sigma)$ die Lebesgue-Dichte
\begin{align*}
h(x) &= \frac{1}{(2\pi)^\frac{d}{2} (\det \Sigma)^\frac12} \exp\left(-\frac12 (x - \mu)^T \Sigma^{-1}(x-\mu)\right)\text{.}
\end{align*}
Für $X \sim \sN(\mu, \Sigma)$ mit $X = (X_1, \ldots, X_d)$ gilt $\E X_i = \mu_i$ und $\Cov(X_i, X_j) := \E X_iX_j - \E X_i\E X_j = \Sigma_{ij}$ für alle $i, j = 1, \ldots, d$. Daher nennen wir $\Sigma$ auch \deftxt{Kovarianzmatrix}\index{Kovarianzmatrix}.

\begin{lemma}\label{Nummer5.1.2}
Es sei $X \sim \sN(\mu, \Sigma)$, dann sind die Komponenten $X_1, \ldots, X_d$ unabhängig genau dann, wenn $\Sigma$ eine Diagonalmatrix ist, wenn also $\Sigma_{ij} = 0$ für alle $i \neq j$ gilt.
\end{lemma}

\begin{beweis}
Der Beweis findet sich in \cite[Satz 7.33]{MEINTRUP}.
\end{beweis}

\begin{satz}\label{Nummer5.1.3}
Eine Zufallsvariable $X$ ist genau dann multivariat normalverteilt, wenn für alle $t \in \R^d \setminus \{0\}$ gilt, dass $\sum_{i=1}^d t_i X_i$ normalverteilt ist.
\end{satz}

\begin{beweis}
Der Beweis findet sich in \cite[Satz 7.35]{MEINTRUP}.
\end{beweis}

\begin{definition}[Gauß-Prozess]\label{Nummer5.1.4}
Ein stochastischer Prozess heißt \deftxt{Gauß-Prozess}\index{Gauß-Prozess}, wenn jede endlich-dimensionale Randverteilung multivariat normalverteilt ist.
\end{definition}

Wir werden sehen, dass Wiener-Prozesse auch Gauß-Prozesse sind. Dies wollen wir im Folgenden näher diskutieren.

\begin{lemma}\label{Nummer5.1.5}
Sei $\mu\colon [0, \infty) \to \R$ und $\Gamma\colon [0, \infty) \times [0, \infty) \to \R$ symmetrisch und strikt positiv definit, dann gibt es einen Gauß-Prozess $(X_t)_{t \geq 0}$ mit $\E X_t = \mu(t)$ für $t \geq 0$ und $\Cov(X_t, X_s) = \Gamma(t, s)$ für $t, s \geq 0$. 

Ist $(Y_t)$ ein weiterer stochastischer Prozess dieser Art, so haben $(X_t)$ und $(Y_t)$ die gleichen endlich-dimensionalen Randverteilungen.
\end{lemma}

\begin{beweis}
Wir werden den Beweis hier nicht führen und überlassen ihn zur Übung.
\end{beweis}

\begin{satz}[Wiener-Prozess als Gauß-Prozess]\label{Nummer5.1.6}
Sei $(W_t)_{t \geq 0}$ ein stochastischer Prozess. Dann sind folgende Aussagen äquivalent:
\begin{enumerate}
	\item\label{N516A1} $(W_t)$ ist ein Wiener-Prozess.
	\item\label{N516A2} $(W_t)$ ist ein stetiger, zentrierter Gauß-Prozess (es gilt also $\E W_t = 0$ für alle $t \geq 0$) mit der Kovarianzfunktion $\Gamma(s,t) = \min\{s,t\}$ für alle $s, t \geq 0$.
\end{enumerate}
\end{satz}

\begin{beweis}
Wir betrachten zunächst \ref{N516A1} $\Rightarrow$ \ref{N516A2}. Die Stetigkeit ist klar und für die Zentriertheit betrachten wir $\E W_t = \E (W_t - W_0) = 0$. Für beliebige $t_1 < t_2 < \ldots < t_n$ sind $W_{t_0}, W_{t_1} - W_{t_0}, \ldots, W_{t_n} - W_{t_{n-1}}$ unabhängig und normalverteilt. Die gemeinsame Verteilung ist dann multivariat normal. Nach Satz \ref{Nummer5.1.3} ist dann jede nicht-triviale Linearkombination der Zuwächse normalverteilt. Dann ist auch jede nicht-triviale Linearkombination von $W_{t_1}, \ldots, W_{t_n}$ normalverteilt und wieder mit Satz \ref{Nummer5.1.3} folgt, dass $(W_{t_1}, \ldots, W_{t_n})$ multivariat normalverteilt ist. Damit ist $(W_t)$ ein Gauß-Prozess. Für $s \leq t$ gilt
\begin{align*}
\Cov(W_t, W_s) &= \E W_tW_s - \E W_t \E W_s = \E W_tW_s = \E (W_t - W_s + W_s)W_s = \E (W_t - W_s)W_s + \E W_s^2\\
\quad &= \E (W_t - W_s)(W_s - W_0) + s = \E (W_t - W_s)\E(W_s - W_0) + s\\
\quad &= s\text{.}
\end{align*}
Wegen $s \leq t$ ist $\Gamma(s,t) = \min\{s,t\} = s$ und wir haben daher auch diese Eigenschaft gezeigt.

Für \ref{N516A2} $\Rightarrow$ \ref{N516A1} ist die Stetigkeit klar, da wir diese voraussetzen. Ferner gilt $\E W_0 = 0$ und $\Var W_0 = \Cov(W_0, W_0) = 0$ und wir erhalten $W_0 = 0$ $P$-fast sicher. Nach Satz \ref{Nummer5.1.3} ist jeder Zuwachs $W_{s+t} - W_s$ normalverteilt und es gilt $\E (W_{s+t} - W_s) = 0$ und
\begin{align*}
\Var (W_{s+t} - W_s) &= \E (W_{s+t} - W_s)^2 = \E W_{s+t}^2 - 2 \E W_{s+t}W_s + \E W_s^2\\
\quad &= \Gamma(s+t, s+t) - 2\Gamma(s+t,s) + \Gamma(s,s) = s+t - 2s + s\\
\quad &= t\text{,} 
\end{align*}
also gilt $W_{s+t} - W_s \sim \sN(0,t)$. Sei nun $0 \leq t_0 < \ldots < t_n$. Da wir einen Gauß-Prozess haben, ist $(W_{t_1}, \ldots, W_{t_n})$ multivariat normalverteilt und mit Satz \ref{Nummer5.1.3} folgt, dass jede nicht-triviale Linearkombination der Komponenten normalverteilt ist, damit auch jede nicht-triviale Linearkombination von $W_{t_1}, W_{t_2} - W_{t_1}, \ldots, W_{t_n} - W_{t_{n-1}}$ normalverteilt und wieder mit Satz \ref{Nummer5.1.3} ist daher $(W_{t_1}, W_{t_2} - W_{t_1}, \ldots, W_{t_n} - W_{t_{n-1}})$ multivariat normalverteilt. Für $i < j$ gilt ferner
\begin{align*}
\Cov(W_{t_i} - W_{t_{i-1}}, & W_{t_j} - W_{t_{j-1}})\\
\quad &= \E (W_{t_i} - W_{t_{i-1}})(W_{t_j} - W_{t_{j-1}})\\
\quad &= \E W_{t_i} W_{t_j} - \E W_{t_i}W_{t_{j-1}} - \E W_{t_{i-1}}W_{t_j} + \E W_{t_{i-1}}W_{t_{j-1}}\\
\quad &= \Cov (W_{t_i}, W_{t_j}) - \Cov (W_{t_i}, W_{t_{j-1}}) - \Cov(W_{t_{i-1}}, W_{t_j}) + \Cov(W_{t_{i-1}}, W_{t_{j-1}})\\
\quad &= \Gamma(t_i, t_j) - \Gamma(t_i, t_{j-1}) - \Gamma(t_{i-1}, t_j) + \Gamma (t_{i-1}, t_{j-1})\\
\quad &= t_i - t_i - t_i + t_i\\
\quad &= 0\text{.}
\end{align*}
Damit sind die Zuwächse nach Lemma \ref{Nummer5.1.2} unabhängig.
\end{beweis}

\begin{korollar}\label{Nummer5.1.7}
Ist $(W_t)_{t \geq 0}$ ein Wiener-Prozess, so sind auch die folgenden Prozesse Wiener-Prozesse:
\begin{enumerate}
	\item $(-W_t)_{t \geq 0}$.
	\item $(W_{s+t} - W_s)_{t \geq 0}$ für festes $s \geq 0$.
	\item $\displaystyle\left(\frac{1}{c} W_{c^2 t}\right)_{t \geq 0}$ für festes $c > 0$.
	\item $(W_{t_0} - W_{t_0 - t})_{t \in [0, t_0]}$ für festes $t_0 > 0$.
\end{enumerate}
\end{korollar}

\begin{beweis}
Der Beweis wird zur Übung überlassen.
\end{beweis}

Korollar \ref{Nummer5.1.7} besagt also unter anderem, dass der Neustart zur Zeit $s$ wieder einen Wiener-Prozess ergibt, dass ein Prozess in der Zeit umskaliert werden kann und, bis auf einen Faktor, die Trajektorien gleich aussehen.

\begin{lemma}\label{Nummer5.1.8}
Es sei $(X_t)$ ein stochastischer Prozess mit $X_0 = 0$. Dann sind die folgenden Aussagen äquivalent:
\begin{enumerate}
	\item\label{N518A1} Der Prozess $(X_t)$ hat unabhängige Zuwächse.
	\item\label{N518A2} Für alle $t \geq s \geq 0$ ist $X_t - X_s$ von $\sigma(X_r : r \leq s)$ unabhängig.
\end{enumerate}
\end{lemma}

\begin{beweis}
Wir betrachten \ref{N518A1} $\Rightarrow$ \ref{N518A2} und fixieren $0 \leq s \leq t$. Für $n \geq 1$ und $0 \leq s_0 < s_1 < \ldots < s_n = s$ gilt dann
\begin{align*}
\sigma(X_{s_0}, X_{s_1}, \ldots, X_{s_n}) &= \sigma(X_{s_0}, X_{s_1} - X_{s_0}, \ldots, X_{s_n} - X_{s_{n-1}})\text{.}
\end{align*}
Diese $\sigma$-Algebra ist nach Voraussetzung von $X_t - X_s$ unabhängig. Damit erhalten wir, dass
\begin{align*}
\bigcup_{n=1}^\infty \left\{ (X_{s_0}, X_{s_1}, \ldots, X_{s_n}) : 0 \leq s_0 < s_1 < \ldots < s_n = s\right\}
\end{align*} 
von $X_t - X_s$ unabhängig ist und dies ist außerdem ein $\cap$-stabiles Erzeugendensystem von $\sigma(X_r : r \leq s)$.

Die Richtung \ref{N518A2} $\Rightarrow$ \ref{N518A1} ist klar.
\end{beweis}

\begin{korollar}[Markov-Eigenschaft]\label{Nummer5.1.9}
Sei $(W_t)$ ein Wiener-Prozess und $s \geq 0$. Dann ist der Wiener-Prozess $(W_{s+t} - W_s)_{t \geq 0}$ von $\sigma(X_r : r \leq s)$ unabhängig.
\end{korollar}

\begin{beweis}
Dass tatsächlich ein Wiener-Prozess vorliegt folgt aus Satz \ref{Nummer5.1.7}, die Unabhängigkeit folgt mit Lemma \ref{Nummer5.1.8}.
\end{beweis}